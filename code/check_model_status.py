#!/usr/bin/env python3
"""
æ£€æŸ¥å½“å‰æ¨¡å‹è®­ç»ƒçŠ¶æ€
"""
import torch
import os
from datetime import datetime

def check_model_status():
    """æ£€æŸ¥æ¨¡å‹è®­ç»ƒçŠ¶æ€"""
    print("ğŸ” æ£€æŸ¥æ¨¡å‹è®­ç»ƒçŠ¶æ€")
    print("=" * 60)
    
    # æ£€æŸ¥ç‚¹è·¯å¾„
    checkpoint_dir = r"pdec_work\checkpoints\multilingual_æ–¹æ¡ˆ1_ä¸‰è¯­è¨€\1"
    
    if not os.path.exists(checkpoint_dir):
        print("âŒ æ£€æŸ¥ç‚¹ç›®å½•ä¸å­˜åœ¨")
        return
    
    # æ£€æŸ¥æ–‡ä»¶
    files = os.listdir(checkpoint_dir)
    print(f"ğŸ“ æ£€æŸ¥ç‚¹æ–‡ä»¶:")
    for f in files:
        if f.endswith('.pt'):
            size = os.path.getsize(os.path.join(checkpoint_dir, f)) / (1024**3)
            print(f"  {f}: {size:.1f}GB")
    
    # åŠ è½½æœ€ä½³æ£€æŸ¥ç‚¹
    best_checkpoint = os.path.join(checkpoint_dir, "checkpoint_best.pt")
    if os.path.exists(best_checkpoint):
        print(f"\nğŸ“Š åˆ†ææœ€ä½³æ£€æŸ¥ç‚¹...")
        try:
            checkpoint = torch.load(best_checkpoint, map_location='cpu')
            
            # åŸºæœ¬ä¿¡æ¯
            extra_state = checkpoint.get('extra_state', {})
            
            print(f"è®­ç»ƒè½®æ•°: {extra_state.get('epoch', 'N/A')}")
            print(f"æ›´æ–°æ­¥æ•°: {extra_state.get('num_updates', 'N/A')}")
            print(f"æœ€ä½³æŸå¤±: {extra_state.get('best_loss', 'N/A')}")
            
            # å­¦ä¹ ç‡ä¿¡æ¯
            if 'lr_scheduler' in extra_state:
                lr_info = extra_state['lr_scheduler']
                if isinstance(lr_info, dict) and 'lr' in lr_info:
                    print(f"å½“å‰å­¦ä¹ ç‡: {lr_info['lr']}")
            
            # ä¼˜åŒ–å™¨ä¿¡æ¯
            if 'optimizer' in checkpoint:
                opt_state = checkpoint['optimizer']
                if 'state' in opt_state:
                    print(f"ä¼˜åŒ–å™¨çŠ¶æ€: å·²ä¿å­˜")
            
            # æ¨¡å‹å‚æ•°ç»Ÿè®¡
            if 'model' in checkpoint:
                model_state = checkpoint['model']
                total_params = sum(p.numel() for p in model_state.values() if isinstance(p, torch.Tensor))
                print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,} ({total_params/1e6:.1f}M)")
            
            print(f"\nâ° æ£€æŸ¥ç‚¹åˆ›å»ºæ—¶é—´: {datetime.fromtimestamp(os.path.getmtime(best_checkpoint))}")
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
    
    # æ£€æŸ¥è®­ç»ƒè¿›ç¨‹
    print(f"\nğŸ”„ æ£€æŸ¥è®­ç»ƒè¿›ç¨‹...")
    import psutil
    python_processes = []
    for proc in psutil.process_iter(['pid', 'name', 'cmdline', 'cpu_percent', 'memory_info']):
        try:
            if proc.info['name'] and 'python' in proc.info['name'].lower():
                cmdline = ' '.join(proc.info['cmdline']) if proc.info['cmdline'] else ''
                if 'fairseq' in cmdline or 'train' in cmdline:
                    python_processes.append({
                        'pid': proc.info['pid'],
                        'cmd': cmdline[:100] + '...' if len(cmdline) > 100 else cmdline,
                        'cpu': proc.info['cpu_percent'],
                        'memory': proc.info['memory_info'].rss / (1024**3) if proc.info['memory_info'] else 0
                    })
        except (psutil.NoSuchProcess, psutil.AccessDenied):
            continue
    
    if python_processes:
        print("âœ… å‘ç°è®­ç»ƒè¿›ç¨‹:")
        for proc in python_processes:
            print(f"  PID {proc['pid']}: CPU {proc['cpu']:.1f}%, å†…å­˜ {proc['memory']:.1f}GB")
            print(f"    å‘½ä»¤: {proc['cmd']}")
    else:
        print("âŒ æœªå‘ç°æ´»è·ƒçš„è®­ç»ƒè¿›ç¨‹")

if __name__ == "__main__":
    check_model_status() 