#!/usr/bin/env python3
"""
ä¿®å¤ç‰ˆç¿»è¯‘è„šæœ¬
è§£å†³BPEå’Œæ¨¡å‹è¾“å‡ºé—®é¢˜
"""

import os
import sys
import torch
import argparse

def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    ROOT_PATH = r"C:\Users\33491\PycharmProjects\machine"
    FAIRSEQ = os.path.join(ROOT_PATH, "fairseq")
    
    os.chdir(ROOT_PATH)
    sys.path.insert(0, FAIRSEQ)
    sys.path.insert(0, os.path.join(FAIRSEQ, "models", "PhasedDecoder"))
    
    # å¯¼å…¥å¿…è¦æ¨¡å—
    import models.transformer_pdec
    import criterions.label_smoothed_cross_entropy_instruction
    
    return ROOT_PATH, FAIRSEQ

def greedy_decode_fixed(model, src_tokens, src_lengths, tgt_dict, max_len=50):
    """ä¿®å¤çš„è´ªå¿ƒè§£ç """
    device = src_tokens.device
    
    # ç¼–ç 
    encoder_out = model.encoder(src_tokens, src_lengths)
    
    # åˆå§‹åŒ–è§£ç  - ä»EOSå¼€å§‹è€Œä¸æ˜¯BOS
    generated = torch.LongTensor([[tgt_dict.eos()]]).to(device)
    
    print(f"ğŸ” ç¼–ç å™¨è¾“å‡ºå½¢çŠ¶: {encoder_out['encoder_out'][0].shape}")
    print(f"ğŸ” å¼€å§‹è§£ç ï¼Œåˆå§‹token: {generated[0].tolist()}")
    
    for step in range(max_len):
        print(f"  æ­¥éª¤ {step+1}: å½“å‰åºåˆ— {generated[0].tolist()}")
        
        # è§£ç å½“å‰æ­¥
        decoder_out = model.decoder(generated, encoder_out)
        
        # è·å–æœ€åä¸€ä¸ªä½ç½®çš„logits
        logits = decoder_out[0][:, -1, :]  # [batch_size, vocab_size]
        print(f"  Logitså½¢çŠ¶: {logits.shape}")
        
        # è·å–æ¦‚ç‡åˆ†å¸ƒ
        probs = torch.softmax(logits, dim=-1)
        
        # è·å–top-5æ¦‚ç‡æœ€é«˜çš„tokens
        top_probs, top_indices = torch.topk(probs, 5, dim=-1)
        print(f"  Top-5 tokens: {top_indices[0].tolist()}")
        print(f"  Top-5 probs: {top_probs[0].tolist()}")
        print(f"  Top-5 words: {[tgt_dict[idx.item()] for idx in top_indices[0]]}")
        
        # é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„token
        next_token = top_indices[:, 0:1]  # å–ç¬¬ä¸€ä¸ªï¼ˆæ¦‚ç‡æœ€é«˜çš„ï¼‰
        
        # æ·»åŠ åˆ°ç”Ÿæˆåºåˆ—
        generated = torch.cat([generated, next_token], dim=1)
        
        print(f"  é€‰æ‹©token: {next_token.item()} ({tgt_dict[next_token.item()]})")
        
        # å¦‚æœç”Ÿæˆäº†ç»“æŸtokenï¼Œåœæ­¢
        if next_token.item() == tgt_dict.eos():
            print(f"  é‡åˆ°EOSï¼Œåœæ­¢ç”Ÿæˆ")
            break
    
    return generated

def translate_sentence_fixed(model, src_dict, tgt_dict, sentence, device):
    """ä¿®å¤çš„ç¿»è¯‘å‡½æ•°"""
    print(f"\nğŸ”„ ç¿»è¯‘: '{sentence}'")
    
    # é¢„å¤„ç†å¥å­
    sentence = sentence.lower().strip()
    
    # TokenåŒ–
    tokens = src_dict.encode_line(sentence, add_if_not_exist=False)
    print(f"ğŸ“ è¾“å…¥tokens: {tokens.tolist()}")
    print(f"ğŸ“ è¾“å…¥words: {[src_dict[t.item()] for t in tokens]}")
    
    # å‡†å¤‡è¾“å…¥
    src_tokens = tokens.unsqueeze(0).to(device)
    src_lengths = torch.LongTensor([src_tokens.size(1)]).to(device)
    
    print(f"ğŸ“ è¾“å…¥å½¢çŠ¶: {src_tokens.shape}")
    
    # æ‰§è¡Œç¿»è¯‘
    with torch.no_grad():
        generated = greedy_decode_fixed(model, src_tokens, src_lengths, tgt_dict)
    
    # è§£ç ç»“æœ
    generated_tokens = generated[0].tolist()
    print(f"ğŸ“ å®Œæ•´è¾“å‡ºtokens: {generated_tokens}")
    
    # æ‰‹åŠ¨è½¬æ¢ä¸ºæ–‡æœ¬ï¼ˆé¿å…BPEé—®é¢˜ï¼‰
    words = []
    for token in generated_tokens:
        word = tgt_dict[token]
        if word not in ['<s>', '</s>', '<pad>']:
            words.append(word)
    
    # ç®€å•çš„æ–‡æœ¬æ¸…ç†
    translation = ' '.join(words)
    translation = translation.replace('<unk>', '[UNK]')
    
    print(f"âœ… ç¿»è¯‘ç»“æœ: '{translation}'")
    return translation

def debug_model_info(model, src_dict, tgt_dict):
    """è°ƒè¯•æ¨¡å‹ä¿¡æ¯"""
    print("\nğŸ” æ¨¡å‹è°ƒè¯•ä¿¡æ¯")
    print("=" * 40)
    
    print(f"ğŸ“‹ æ¨¡å‹ç±»å‹: {type(model)}")
    print(f"ğŸ“‹ ç¼–ç å™¨å±‚æ•°: {len(model.encoder.layers)}")
    print(f"ğŸ“‹ è§£ç å™¨å±‚æ•°: {len(model.decoder.layers)}")
    print(f"ğŸ“‹ è¯æ±‡è¡¨å¤§å°: {len(src_dict)}")
    
    # æ£€æŸ¥ä¸€äº›å¸¸è§è¯æ±‡
    test_words = ['hello', 'the', 'and', 'you', 'are']
    print(f"\nğŸ“ è¯æ±‡è¡¨æµ‹è¯•:")
    for word in test_words:
        if word in src_dict.indices:
            idx = src_dict.indices[word]
            print(f"  '{word}' -> {idx}")
        else:
            print(f"  '{word}' -> ä¸åœ¨è¯æ±‡è¡¨ä¸­")

def main():
    print("ğŸš€ ä¿®å¤ç‰ˆç¿»è¯‘æµ‹è¯•")
    print("=" * 60)
    
    try:
        # è®¾ç½®ç¯å¢ƒ
        ROOT_PATH, FAIRSEQ = setup_environment()
        print("âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ")
        
        # å¯¼å…¥fairseqæ¨¡å—
        from fairseq import checkpoint_utils
        from fairseq.data import Dictionary
        
        print("âœ… fairseqæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # åŠ è½½æ¨¡å‹
        model_path = "pdec_work/checkpoints/europarl_test/1/checkpoint_best_fixed.pt"
        data_bin = "fairseq/models/ZeroTrans/europarl_scripts/build_data/europarl_15-bin"
        
        print(f"ğŸ” åŠ è½½æ¨¡å‹: {model_path}")
        models, model_args = checkpoint_utils.load_model_ensemble([model_path])
        model = models[0]
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # åŠ è½½å­—å…¸
        dict_path = os.path.join(data_bin, "dict.en.txt")
        src_dict = Dictionary.load(dict_path)
        tgt_dict = src_dict  # å…±äº«å­—å…¸
        
        print(f"âœ… å­—å…¸åŠ è½½æˆåŠŸï¼Œå¤§å°: {len(src_dict)}")
        
        # è®¾ç½®è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        model.eval()
        
        print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
        
        # è°ƒè¯•æ¨¡å‹ä¿¡æ¯
        debug_model_info(model, src_dict, tgt_dict)
        
        # æµ‹è¯•ç¿»è¯‘
        test_sentences = [
            "hello",
            "thank you"
        ]
        
        print("\n" + "="*60)
        print("ğŸŒ å¼€å§‹è¯¦ç»†ç¿»è¯‘æµ‹è¯•")
        print("="*60)
        
        for i, sentence in enumerate(test_sentences, 1):
            print(f"\nã€æµ‹è¯• {i}ã€‘")
            try:
                translation = translate_sentence_fixed(model, src_dict, tgt_dict, sentence, device)
                print(f"ğŸ¯ æœ€ç»ˆç»“æœ: {sentence} -> {translation}")
            except Exception as e:
                print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        print("\nğŸ‰ è°ƒè¯•æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 