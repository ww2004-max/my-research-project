#!/usr/bin/env python3
"""
ä¿®å¤ç»§ç»­è®­ç»ƒcheckpointçš„argså­—æ®µ
"""

import torch
import os
from omegaconf import OmegaConf

def fix_continue_checkpoint():
    """ä¿®å¤ç»§ç»­è®­ç»ƒçš„checkpoint"""
    print("ğŸ”§ ä¿®å¤ç»§ç»­è®­ç»ƒçš„Checkpoint")
    print("=" * 60)
    
    checkpoint_path = "pdec_work/checkpoints/europarl_continue_5epochs/checkpoint_best.pt"
    fixed_path = "pdec_work/checkpoints/europarl_continue_5epochs/checkpoint_best_fixed.pt"
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ åŸå§‹checkpointä¸å­˜åœ¨: {checkpoint_path}")
        return False
    
    try:
        # åŠ è½½checkpoint
        print(f"ğŸ“‚ åŠ è½½: {checkpoint_path}")
        state = torch.load(checkpoint_path, map_location='cpu')
        
        print("âœ… CheckpointåŠ è½½æˆåŠŸ")
        print(f"ğŸ“Š Keys: {list(state.keys())}")
        
        # æ£€æŸ¥argså­—æ®µ
        if 'args' not in state or state['args'] is None:
            print("âš ï¸  argså­—æ®µç¼ºå¤±æˆ–ä¸ºç©ºï¼Œéœ€è¦ä¿®å¤")
            
            # ä»cfgé‡å»ºargs
            if 'cfg' in state and state['cfg'] is not None:
                cfg = state['cfg']
                print("ğŸ” ä»cfgé‡å»ºargs...")
                
                # è½¬æ¢cfgä¸ºargsæ ¼å¼
                args = OmegaConf.create({})
                
                # å¤åˆ¶å…³é”®é…ç½®
                if hasattr(cfg, 'model'):
                    args.update(cfg.model)
                if hasattr(cfg, 'task'):
                    args.update(cfg.task)
                if hasattr(cfg, 'dataset'):
                    args.update(cfg.dataset)
                if hasattr(cfg, 'optimization'):
                    args.update(cfg.optimization)
                if hasattr(cfg, 'checkpoint'):
                    args.update(cfg.checkpoint)
                if hasattr(cfg, 'common'):
                    args.update(cfg.common)
                if hasattr(cfg, 'distributed_training'):
                    args.update(cfg.distributed_training)
                
                # è®¾ç½®args
                state['args'] = args
                print("âœ… argså­—æ®µé‡å»ºå®Œæˆ")
            else:
                print("âŒ cfgå­—æ®µä¹Ÿä¸å­˜åœ¨ï¼Œæ— æ³•ä¿®å¤")
                return False
        else:
            print("âœ… argså­—æ®µå­˜åœ¨")
        
        # æ£€æŸ¥è®­ç»ƒä¿¡æ¯
        if 'extra_state' in state:
            extra = state['extra_state']
            print(f"\nğŸ“Š è®­ç»ƒä¿¡æ¯:")
            for key, value in extra.items():
                if isinstance(value, (int, float, str)):
                    print(f"   {key}: {value}")
        
        # ä¿å­˜ä¿®å¤åçš„checkpoint
        print(f"\nğŸ’¾ ä¿å­˜ä¿®å¤åçš„checkpoint: {fixed_path}")
        torch.save(state, fixed_path)
        print("âœ… ä¿å­˜æˆåŠŸ")
        
        # éªŒè¯ä¿®å¤ç»“æœ
        print(f"\nğŸ” éªŒè¯ä¿®å¤ç»“æœ...")
        test_state = torch.load(fixed_path, map_location='cpu')
        if 'args' in test_state and test_state['args'] is not None:
            print("âœ… ä¿®å¤éªŒè¯æˆåŠŸ")
            return True
        else:
            print("âŒ ä¿®å¤éªŒè¯å¤±è´¥")
            return False
        
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_fixed_test_script():
    """åˆ›å»ºä½¿ç”¨ä¿®å¤åcheckpointçš„æµ‹è¯•è„šæœ¬"""
    print(f"\nğŸ“ åˆ›å»ºä½¿ç”¨ä¿®å¤checkpointçš„æµ‹è¯•è„šæœ¬")
    
    script_content = '''#!/usr/bin/env python3
"""
ä½¿ç”¨ä¿®å¤åçš„ç»§ç»­è®­ç»ƒcheckpointè¿›è¡Œæµ‹è¯•
"""

import torch
import sys
import os

# æ·»åŠ fairseqè·¯å¾„
sys.path.insert(0, 'fairseq')

def test_fixed_continue_model():
    """æµ‹è¯•ä¿®å¤åçš„ç»§ç»­è®­ç»ƒæ¨¡å‹"""
    print("ğŸ›ï¸ æµ‹è¯•ä¿®å¤åçš„ç»§ç»­è®­ç»ƒæ¨¡å‹")
    print("=" * 60)
    
    try:
        from fairseq import checkpoint_utils, tasks
        
        # ä½¿ç”¨ä¿®å¤åçš„checkpoint
        checkpoint_path = "pdec_work/checkpoints/europarl_continue_5epochs/checkpoint_best_fixed.pt"
        data_path = "fairseq/models/ZeroTrans/europarl_scripts/build_data/europarl_15-bin"
        
        print(f"ğŸ” åŠ è½½æ¨¡å‹: {checkpoint_path}")
        
        if not os.path.exists(checkpoint_path):
            print(f"âŒ ä¿®å¤åçš„checkpointä¸å­˜åœ¨: {checkpoint_path}")
            print("è¯·å…ˆè¿è¡Œ: python fix_continue_checkpoint.py")
            return
        
        # åŠ è½½checkpoint
        state = checkpoint_utils.load_checkpoint_to_cpu(checkpoint_path)
        cfg = state['cfg']
        
        # è®¾ç½®ä»»åŠ¡
        task = tasks.setup_task(cfg.task)
        task.load_dataset('train', combine=False, epoch=1)
        
        # æ„å»ºæ¨¡å‹
        models, _model_args = checkpoint_utils.load_model_ensemble([checkpoint_path], task=task)
        model = models[0]
        model.eval()
        
        if torch.cuda.is_available():
            model.cuda()
        
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•ç¿»è¯‘
        test_sentences = [
            "The European Parliament",
            "We must consider this proposal", 
            "This is very important",
            "The Commission has presented",
            "I would like to thank"
        ]
        
        print(f"\nğŸ§ª ç¿»è¯‘æµ‹è¯• (ç»§ç»­è®­ç»ƒ5è½®åçš„æ¨¡å‹):")
        for sentence in test_sentences:
            print(f"\nğŸ”„ ç¿»è¯‘: '{sentence}'")
            
            # ç¼–ç è¾“å…¥
            src_tokens = task.source_dictionary.encode_line(sentence, add_if_not_exist=False).long().unsqueeze(0)
            if torch.cuda.is_available():
                src_tokens = src_tokens.cuda()
            
            # åˆ›å»ºsample
            sample = {
                'net_input': {
                    'src_tokens': src_tokens,
                    'src_lengths': torch.LongTensor([src_tokens.size(1)])
                }
            }
            if torch.cuda.is_available():
                sample['net_input']['src_lengths'] = sample['net_input']['src_lengths'].cuda()
            
            # ç¿»è¯‘
            with torch.no_grad():
                translations = task.inference_step(model, sample, prefix_tokens=None)
            
            # è§£ç ç»“æœ
            hypo = translations[0][0]  # å–æœ€å¥½çš„ç»“æœ
            tokens = hypo['tokens'].cpu()
            score = hypo['score']
            translation = task.target_dictionary.string(tokens, bpe_symbol='@@ ')
            
            print(f"âœ… ç»“æœ: '{translation}' (åˆ†æ•°: {score:.4f})")
        
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆ!")
        print(f"\nğŸ’¡ å¯¹æ¯”ç»“æœ:")
        print("- å¦‚æœç»“æœä»ç„¶æ˜¯é‡å¤çš„ä¸“æœ‰åè¯ï¼Œè¯´æ˜æ¨¡å‹ç¡®å®è¿‡æ‹Ÿåˆäº†")
        print("- å¦‚æœç»“æœæœ‰æ”¹å–„ï¼Œè¯´æ˜ç»§ç»­è®­ç»ƒæœ‰å¸®åŠ©")
        print("- å¯ä»¥å°è¯•ä½¿ç”¨æ›´æ—©çš„checkpointæˆ–è°ƒæ•´è§£ç å‚æ•°")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_fixed_continue_model()
'''
    
    with open("test_fixed_continue_model.py", "w", encoding="utf-8") as f:
        f.write(script_content)
    
    print("âœ… åˆ›å»ºäº† test_fixed_continue_model.py")

def main():
    print("ğŸ”§ ä¿®å¤ç»§ç»­è®­ç»ƒçš„Checkpoint")
    print("=" * 60)
    
    # ä¿®å¤checkpoint
    if fix_continue_checkpoint():
        print(f"\nğŸ‰ ä¿®å¤æˆåŠŸ!")
        
        # åˆ›å»ºæµ‹è¯•è„šæœ¬
        create_fixed_test_script()
        
        print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("1. è¿è¡Œ: python test_fixed_continue_model.py")
        print("2. æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„ç¿»è¯‘ç»“æœ")
        print("3. å¦‚æœä»æœ‰é—®é¢˜ï¼Œè€ƒè™‘å…¶ä»–è§£å†³æ–¹æ¡ˆ")
    else:
        print(f"\nâŒ ä¿®å¤å¤±è´¥")

if __name__ == "__main__":
    main() 