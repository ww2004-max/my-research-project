#!/usr/bin/env python3
import torch
import json

RESTORE_FILE = r"C:\Users\33491\PycharmProjects\machine\pdec_work\checkpoints\europarl_continue_5epochs\checkpoint_best.pt"

def check_detailed_checkpoint():
    """è¯¦ç»†æ£€æŸ¥æœ€ä½³checkpoint"""
    checkpoint_path = RESTORE_FILE
    
    print(f"ğŸ” è¯¦ç»†æ£€æŸ¥æœ€ä½³checkpoint: {checkpoint_path}")
    
    try:
        ckpt = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        
        # æ£€æŸ¥extra_stateçš„è¯¦ç»†ä¿¡æ¯
        if 'extra_state' in ckpt:
            extra = ckpt['extra_state']
            print("\nğŸ“Š Extra Stateè¯¦ç»†ä¿¡æ¯:")
            
            # è®­ç»ƒè¿­ä»£å™¨ä¿¡æ¯
            if 'train_iterator' in extra:
                train_iter = extra['train_iterator']
                print(f"  ğŸ”„ è®­ç»ƒè¿­ä»£å™¨:")
                print(f"    - å½“å‰epoch: {train_iter.get('epoch', 'N/A')}")
                print(f"    - epochå†…è¿­ä»£: {train_iter.get('iterations_in_epoch', 'N/A')}")
                print(f"    - ç‰ˆæœ¬: {train_iter.get('version', 'N/A')}")
                print(f"    - æ˜¯å¦shuffle: {train_iter.get('shuffle', 'N/A')}")
            
            # æœ€ä½³æŒ‡æ ‡ä¿¡æ¯
            if 'best' in extra:
                best = extra['best']
                print(f"  ğŸ† æœ€ä½³æŒ‡æ ‡: {best}")
            
            # éªŒè¯æŸå¤±
            if 'val_loss' in extra:
                val_loss = extra['val_loss']
                print(f"  ğŸ“‰ éªŒè¯æŸå¤±: {val_loss}")
            
            # æŒ‡æ ‡ä¿¡æ¯
            if 'metrics' in extra:
                metrics = extra['metrics']
                print(f"  ğŸ“ˆ æŒ‡æ ‡ä¿¡æ¯:")
                if isinstance(metrics, dict):
                    for key, value in metrics.items():
                        print(f"    - {key}: {value}")
                else:
                    print(f"    - {metrics}")
            
            # è®­ç»ƒæ—¶é—´
            if 'previous_training_time' in extra:
                training_time = extra['previous_training_time']
                print(f"  â±ï¸ ä¹‹å‰è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’ ({training_time/3600:.2f}å°æ—¶)")
        
        # æ£€æŸ¥ä¼˜åŒ–å™¨å†å²
        if 'optimizer_history' in ckpt and ckpt['optimizer_history']:
            opt_history = ckpt['optimizer_history']
            print(f"\nğŸ”§ ä¼˜åŒ–å™¨å†å² (å…±{len(opt_history)}ä¸ªçŠ¶æ€):")
            
            # æ˜¾ç¤ºæœ€åä¸€ä¸ªä¼˜åŒ–å™¨çŠ¶æ€
            if opt_history:
                last_opt = opt_history[-1]
                print(f"  ğŸ“‹ æœ€åä¼˜åŒ–å™¨çŠ¶æ€é”®: {list(last_opt.keys())}")
                
                if 'lr' in last_opt:
                    print(f"  ğŸ“Š å½“å‰å­¦ä¹ ç‡: {last_opt['lr']}")
                if 'num_updates' in last_opt:
                    print(f"  ğŸ”¢ æ›´æ–°æ­¥æ•°: {last_opt['num_updates']}")
                if 'epoch' in last_opt:
                    print(f"  ğŸ“… Epoch: {last_opt['epoch']}")
        
        # æ£€æŸ¥args
        if 'args' in ckpt:
            args = ckpt['args']
            print(f"\nâš™ï¸ è®­ç»ƒå‚æ•°:")
            important_args = ['max_epoch', 'lr', 'max_tokens', 'update_freq', 'save_interval']
            for arg in important_args:
                if hasattr(args, arg):
                    print(f"  - {arg}: {getattr(args, arg)}")
        
        print("\nâœ… è¯¦ç»†æ£€æŸ¥å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥å‡ºé”™: {e}")

if __name__ == "__main__":
    check_detailed_checkpoint() 