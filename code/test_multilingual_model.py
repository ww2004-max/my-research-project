#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šè¯­è¨€æ¨¡å‹æµ‹è¯•è„šæœ¬
"""

import os
import sys
import torch

def test_multilingual_model():
    """æµ‹è¯•å¤šè¯­è¨€æ¨¡å‹"""
    print("ğŸŒ å¤šè¯­è¨€æ¨¡å‹æµ‹è¯•")
    print("=" * 60)
    
    # è·¯å¾„é…ç½®
    ROOT_PATH = r"C:\Users\33491\PycharmProjects\machine"
    FAIRSEQ_PATH = os.path.join(ROOT_PATH, "fairseq")
    
    # æ·»åŠ è·¯å¾„
    sys.path.insert(0, os.path.abspath('fairseq'))
    
    # å¯èƒ½çš„æ¨¡å‹è·¯å¾„
    model_paths = {
        "æ–¹æ¡ˆ1_ä¸‰è¯­è¨€": "pdec_work/checkpoints/multilingual_æ–¹æ¡ˆ1_ä¸‰è¯­è¨€/1/checkpoint_best.pt",
        "æ–¹æ¡ˆ2_å››è¯­è¨€": "pdec_work/checkpoints/multilingual_æ–¹æ¡ˆ2_å››è¯­è¨€/1/checkpoint_best.pt", 
        "æ–¹æ¡ˆ3_äº”è¯­è¨€": "pdec_work/checkpoints/multilingual_æ–¹æ¡ˆ3_äº”è¯­è¨€/1/checkpoint_best.pt",
        "æ–¹æ¡ˆ4_æ¬§æ´²ä¸»è¦è¯­è¨€": "pdec_work/checkpoints/multilingual_æ–¹æ¡ˆ4_æ¬§æ´²ä¸»è¦è¯­è¨€/1/checkpoint_best.pt",
        "åŒå‘æ¨¡å‹": "pdec_work/checkpoints/europarl_bidirectional/1/checkpoint_best.pt"
    }
    
    # æ£€æŸ¥å¯ç”¨æ¨¡å‹
    available_models = {}
    for name, path in model_paths.items():
        if os.path.exists(path):
            size = os.path.getsize(path) / (1024*1024)  # MB
            available_models[name] = {"path": path, "size": size}
            print(f"âœ… å‘ç°æ¨¡å‹: {name} ({size:.1f}MB)")
        else:
            print(f"âŒ æ¨¡å‹ä¸å­˜åœ¨: {name}")
    
    if not available_models:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„å¤šè¯­è¨€æ¨¡å‹")
        return
    
    # æµ‹è¯•å¥å­
    test_sentences = {
        'en': [
            "Hello, how are you?",
            "I am fine, thank you.",
            "What is your name?",
            "Where are you from?",
            "Good morning.",
            "Have a nice day."
        ],
        'de': [
            "Hallo, wie geht es dir?",
            "Mir geht es gut, danke.",
            "Wie heiÃŸt du?",
            "Woher kommst du?",
            "Guten Morgen.",
            "Hab einen schÃ¶nen Tag."
        ],
        'es': [
            "Hola, Â¿cÃ³mo estÃ¡s?",
            "Estoy bien, gracias.",
            "Â¿CÃ³mo te llamas?",
            "Â¿De dÃ³nde eres?",
            "Buenos dÃ­as.",
            "Que tengas un buen dÃ­a."
        ],
        'it': [
            "Ciao, come stai?",
            "Sto bene, grazie.",
            "Come ti chiami?",
            "Di dove sei?",
            "Buongiorno.",
            "Buona giornata."
        ]
    }
    
    # è¯­è¨€å¯¹é…ç½®
    language_pairs = {
        "æ–¹æ¡ˆ1_ä¸‰è¯­è¨€": [('en', 'de'), ('de', 'en'), ('en', 'es'), ('es', 'en'), ('de', 'es'), ('es', 'de')],
        "æ–¹æ¡ˆ2_å››è¯­è¨€": [('en', 'de'), ('de', 'en'), ('en', 'es'), ('es', 'en'), ('en', 'it'), ('it', 'en'), 
                        ('de', 'es'), ('es', 'de'), ('de', 'it'), ('it', 'de'), ('es', 'it'), ('it', 'es')],
        "åŒå‘æ¨¡å‹": [('en', 'de'), ('de', 'en'), ('en', 'es'), ('es', 'en'), ('en', 'it'), ('it', 'en')]
    }
    
    # æµ‹è¯•æ¯ä¸ªå¯ç”¨æ¨¡å‹
    for model_name, model_info in available_models.items():
        print(f"\nğŸ¯ æµ‹è¯•æ¨¡å‹: {model_name}")
        print("-" * 60)
        
        try:
            # åŠ è½½æ¨¡å‹
            checkpoint = torch.load(model_info["path"], map_location='cpu')
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"ğŸ“Š æ¨¡å‹å¤§å°: {model_info['size']:.1f}MB")
            
            # æ£€æŸ¥æ¨¡å‹é…ç½®
            if 'cfg' in checkpoint:
                cfg = checkpoint['cfg']
                if hasattr(cfg, 'model') and hasattr(cfg.model, 'langs'):
                    print(f"ğŸŒ æ”¯æŒè¯­è¨€: {cfg.model.langs}")
                if hasattr(cfg, 'task') and hasattr(cfg.task, 'lang_pairs'):
                    pairs = cfg.task.lang_pairs.split(',')
                    print(f"ğŸ”„ ç¿»è¯‘æ–¹å‘: {len(pairs)} ä¸ª")
                    for i, pair in enumerate(pairs[:6]):  # æ˜¾ç¤ºå‰6ä¸ª
                        print(f"   {i+1}. {pair}")
                    if len(pairs) > 6:
                        print(f"   ... è¿˜æœ‰ {len(pairs)-6} ä¸ª")
            
            # ç®€å•ç¼–ç æµ‹è¯•
            print(f"\nğŸ” ç¼–ç æµ‹è¯•:")
            
            # æµ‹è¯•ä¸åŒè¯­è¨€çš„å¥å­ç¼–ç 
            for lang, sentences in test_sentences.items():
                if lang in ['en', 'de', 'es', 'it']:  # ä¸»è¦æµ‹è¯•è¯­è¨€
                    test_sentence = sentences[0]  # å–ç¬¬ä¸€ä¸ªå¥å­
                    print(f"  {lang}: {test_sentence}")
                    
                    # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„ç¼–ç æµ‹è¯•
                    # ç”±äºéœ€è¦å®Œæ•´çš„fairseqç¯å¢ƒï¼Œè¿™é‡ŒåªåšåŸºæœ¬æ£€æŸ¥
                    print(f"    âœ… å¥å­é•¿åº¦: {len(test_sentence.split())} è¯")
            
            print(f"âœ… {model_name} æµ‹è¯•å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ {model_name} æµ‹è¯•å¤±è´¥: {e}")
    
    print(f"\nğŸ“‹ æµ‹è¯•æ€»ç»“:")
    print("=" * 60)
    print(f"âœ… å¯ç”¨æ¨¡å‹: {len(available_models)} ä¸ª")
    
    for name, info in available_models.items():
        print(f"  â€¢ {name}: {info['size']:.1f}MB")
    
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("1. å¦‚æœæœ‰å¤šä¸ªæ¨¡å‹ï¼Œé€‰æ‹©æœ€æ–°è®­ç»ƒçš„")
    print("2. æ–¹æ¡ˆ2_å››è¯­è¨€ æ”¯æŒæœ€å¤šç¿»è¯‘æ–¹å‘ (12ä¸ª)")
    print("3. å¯ä»¥ä½¿ç”¨ working_translate.py è¿›è¡Œå®é™…ç¿»è¯‘æµ‹è¯•")

if __name__ == "__main__":
    test_multilingual_model() 