#!/usr/bin/env python3
"""
Europarlé£æ ¼ç¿»è¯‘æµ‹è¯•
ä½¿ç”¨æ¨¡å‹è®­ç»ƒåŸŸå†…çš„å¥å­è¿›è¡Œæµ‹è¯•
"""

import os
import sys
import torch

def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    ROOT_PATH = r"C:\Users\33491\PycharmProjects\machine"
    FAIRSEQ = os.path.join(ROOT_PATH, "fairseq")
    
    os.chdir(ROOT_PATH)
    sys.path.insert(0, FAIRSEQ)
    sys.path.insert(0, os.path.join(FAIRSEQ, "models", "PhasedDecoder"))
    
    # å¯¼å…¥å¿…è¦æ¨¡å—
    import models.transformer_pdec
    import criterions.label_smoothed_cross_entropy_instruction
    
    return ROOT_PATH, FAIRSEQ

def greedy_decode(model, src_tokens, src_lengths, tgt_dict, max_len=50):
    """è´ªå¿ƒè§£ç """
    device = src_tokens.device
    
    # ç¼–ç 
    encoder_out = model.encoder(src_tokens, src_lengths)
    
    # åˆå§‹åŒ–è§£ç 
    generated = torch.LongTensor([[tgt_dict.eos()]]).to(device)
    
    for step in range(max_len):
        # è§£ç å½“å‰æ­¥
        decoder_out = model.decoder(generated, encoder_out)
        
        # è·å–æœ€åä¸€ä¸ªä½ç½®çš„logits
        logits = decoder_out[0][:, -1, :]
        
        # è·å–æ¦‚ç‡åˆ†å¸ƒ
        probs = torch.softmax(logits, dim=-1)
        
        # é€‰æ‹©æ¦‚ç‡æœ€é«˜çš„token
        next_token = probs.argmax(dim=-1, keepdim=True)
        
        # æ·»åŠ åˆ°ç”Ÿæˆåºåˆ—
        generated = torch.cat([generated, next_token], dim=1)
        
        # å¦‚æœç”Ÿæˆäº†ç»“æŸtokenï¼Œåœæ­¢
        if next_token.item() == tgt_dict.eos():
            break
    
    return generated

def translate_europarl_sentence(model, src_dict, tgt_dict, sentence, device):
    """ç¿»è¯‘Europarlé£æ ¼å¥å­"""
    print(f"\nğŸ”„ ç¿»è¯‘: '{sentence}'")
    
    # TokenåŒ–
    tokens = src_dict.encode_line(sentence, add_if_not_exist=False)
    print(f"ğŸ“ è¾“å…¥tokens: {tokens.tolist()}")
    
    # æ£€æŸ¥æœªçŸ¥è¯
    unknown_count = (tokens == src_dict.unk()).sum().item()
    if unknown_count > 0:
        print(f"âš ï¸  åŒ…å« {unknown_count} ä¸ªæœªçŸ¥è¯")
    
    # æ˜¾ç¤ºtokenå¯¹åº”çš„è¯
    words = [src_dict[t.item()] for t in tokens]
    print(f"ğŸ“ è¾“å…¥words: {words}")
    
    # å‡†å¤‡è¾“å…¥
    src_tokens = tokens.unsqueeze(0).to(device)
    src_lengths = torch.LongTensor([src_tokens.size(1)]).to(device)
    
    # æ‰§è¡Œç¿»è¯‘
    with torch.no_grad():
        generated = greedy_decode(model, src_tokens, src_lengths, tgt_dict)
    
    # è§£ç ç»“æœ
    generated_tokens = generated[0].tolist()
    print(f"ğŸ“ è¾“å‡ºtokens: {generated_tokens}")
    
    # è½¬æ¢ä¸ºæ–‡æœ¬
    output_words = [tgt_dict[token] for token in generated_tokens]
    print(f"ğŸ“ è¾“å‡ºwords: {output_words}")
    
    # æ¸…ç†è¾“å‡º
    clean_words = []
    for word in output_words:
        if word not in ['<s>', '</s>', '<pad>']:
            # å¤„ç†subword
            if word.startswith('â–'):
                clean_words.append(word[1:])  # å»æ‰â–å‰ç¼€
            else:
                clean_words.append(word)
    
    translation = ' '.join(clean_words)
    print(f"âœ… ç¿»è¯‘ç»“æœ: '{translation}'")
    return translation

def main():
    print("ğŸ›ï¸ Europarlé£æ ¼ç¿»è¯‘æµ‹è¯•")
    print("=" * 60)
    
    try:
        # è®¾ç½®ç¯å¢ƒ
        ROOT_PATH, FAIRSEQ = setup_environment()
        print("âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ")
        
        # å¯¼å…¥fairseqæ¨¡å—
        from fairseq import checkpoint_utils
        from fairseq.data import Dictionary
        
        # åŠ è½½æ¨¡å‹
        model_path = "pdec_work/checkpoints/europarl_test/1/checkpoint_best_fixed.pt"
        data_bin = "fairseq/models/ZeroTrans/europarl_scripts/build_data/europarl_15-bin"
        
        print(f"ğŸ” åŠ è½½æ¨¡å‹: {model_path}")
        models, model_args = checkpoint_utils.load_model_ensemble([model_path])
        model = models[0]
        
        # åŠ è½½å­—å…¸
        dict_path = os.path.join(data_bin, "dict.en.txt")
        src_dict = Dictionary.load(dict_path)
        tgt_dict = src_dict
        
        print(f"âœ… æ¨¡å‹å’Œå­—å…¸åŠ è½½æˆåŠŸ")
        
        # è®¾ç½®è®¾å¤‡
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model = model.to(device)
        model.eval()
        
        # Europarlé£æ ¼çš„æµ‹è¯•å¥å­ï¼ˆæ”¿æ²»/è®®ä¼šè¯­è¨€ï¼‰
        europarl_sentences = [
            "The European Parliament",
            "We must consider this proposal",
            "The Commission has presented",
            "I would like to thank",
            "This is very important",
            "The report shows that",
            "We need to discuss",
            "The committee has decided"
        ]
        
        print("\n" + "="*60)
        print("ğŸ›ï¸ Europarlé£æ ¼ç¿»è¯‘æµ‹è¯• (è‹±è¯­ -> å¾·è¯­)")
        print("="*60)
        
        for i, sentence in enumerate(europarl_sentences, 1):
            print(f"\nã€æµ‹è¯• {i}ã€‘")
            try:
                translation = translate_europarl_sentence(model, src_dict, tgt_dict, sentence, device)
                print(f"ğŸ¯ {sentence} -> {translation}")
            except Exception as e:
                print(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        print("\nğŸ‰ Europarlé£æ ¼æµ‹è¯•å®Œæˆ!")
        print("\nğŸ’¡ æ€»ç»“:")
        print("- ä½ çš„æ¨¡å‹æ˜¯åœ¨æ¬§æ´²è®®ä¼šæ•°æ®ä¸Šè®­ç»ƒçš„")
        print("- å®ƒä¸“é—¨ç”¨äºç¿»è¯‘æ”¿æ²»/è®®ä¼šæ–‡æ¡£")
        print("- å¯¹äºæ—¥å¸¸å¯¹è¯å¯èƒ½æ•ˆæœä¸å¥½")
        print("- ä½†åœ¨å…¶ä¸“ä¸šé¢†åŸŸå†…åº”è¯¥è¡¨ç°è‰¯å¥½")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 