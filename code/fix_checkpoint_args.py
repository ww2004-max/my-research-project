#!/usr/bin/env python3
"""
ä¿®å¤checkpointä¸­çš„argså­—æ®µ
ä»cfgä¸­æå–é…ç½®å¹¶é‡å»ºargs
"""

import os
import sys
import torch
import argparse

def setup_environment():
    """è®¾ç½®ç¯å¢ƒ"""
    ROOT_PATH = r"C:\Users\33491\PycharmProjects\machine"
    FAIRSEQ = os.path.join(ROOT_PATH, "fairseq")
    
    os.chdir(ROOT_PATH)
    sys.path.insert(0, FAIRSEQ)
    
    return ROOT_PATH, FAIRSEQ

def namespace_to_args(namespace_obj):
    """å°†Namespaceå¯¹è±¡è½¬æ¢ä¸ºargs"""
    if hasattr(namespace_obj, '__dict__'):
        return argparse.Namespace(**namespace_obj.__dict__)
    return namespace_obj

def fix_checkpoint_args(checkpoint_path, output_path=None):
    """ä¿®å¤checkpointä¸­çš„argså­—æ®µ"""
    print(f"ğŸ”§ ä¿®å¤checkpoint: {checkpoint_path}")
    
    if not os.path.exists(checkpoint_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
        return False
    
    try:
        # åŠ è½½checkpoint
        state = torch.load(checkpoint_path, map_location='cpu')
        
        # æ£€æŸ¥å½“å‰çŠ¶æ€
        print(f"ğŸ“‹ å½“å‰argsçŠ¶æ€: {type(state.get('args'))}")
        print(f"ğŸ“‹ å½“å‰cfgçŠ¶æ€: {type(state.get('cfg'))}")
        
        if state.get('args') is not None:
            print("âœ… argså·²å­˜åœ¨ï¼Œæ— éœ€ä¿®å¤")
            return True
        
        if 'cfg' not in state:
            print("âŒ æ²¡æœ‰cfgé…ç½®ï¼Œæ— æ³•ä¿®å¤")
            return False
        
        cfg = state['cfg']
        
        # ä»cfgä¸­æå–æ¨¡å‹é…ç½®
        if 'model' in cfg and hasattr(cfg['model'], '__dict__'):
            model_args = namespace_to_args(cfg['model'])
            print(f"âœ… ä»cfg.modelæå–args: {model_args.arch}")
            
            # è®¾ç½®args
            state['args'] = model_args
            
            # ç¡®ä¿å…³é”®å­—æ®µå­˜åœ¨
            if not hasattr(model_args, 'task'):
                model_args.task = 'translation_multi_simple_epoch'
            if not hasattr(model_args, 'arch'):
                model_args.arch = 'transformer_pdec_6_e_6_d'
            
            print(f"ğŸ”§ ä¿®å¤åçš„å…³é”®é…ç½®:")
            print(f"  æ¶æ„: {getattr(model_args, 'arch', 'N/A')}")
            print(f"  ä»»åŠ¡: {getattr(model_args, 'task', 'N/A')}")
            print(f"  è¯­è¨€å¯¹: {getattr(model_args, 'lang_pairs', 'N/A')}")
            
            # ä¿å­˜ä¿®å¤åçš„checkpoint
            if output_path is None:
                output_path = checkpoint_path.replace('.pt', '_fixed.pt')
            
            # å¤‡ä»½åŸæ–‡ä»¶
            backup_path = checkpoint_path + '.backup'
            if not os.path.exists(backup_path):
                torch.save(torch.load(checkpoint_path, map_location='cpu'), backup_path)
                print(f"ğŸ“ å·²å¤‡ä»½åŸæ–‡ä»¶: {backup_path}")
            
            # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
            torch.save(state, output_path)
            print(f"ğŸ’¾ ä¿®å¤åçš„checkpointå·²ä¿å­˜: {output_path}")
            
            return True
        else:
            print("âŒ cfg.modelæ ¼å¼ä¸æ­£ç¡®ï¼Œæ— æ³•æå–args")
            return False
            
    except Exception as e:
        print(f"âŒ ä¿®å¤å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_fixed_checkpoint(checkpoint_path):
    """æµ‹è¯•ä¿®å¤åçš„checkpoint"""
    print(f"\nğŸ§ª æµ‹è¯•ä¿®å¤åçš„checkpoint: {checkpoint_path}")
    
    try:
        # åŠ è½½checkpoint
        state = torch.load(checkpoint_path, map_location='cpu')
        
        args = state.get('args')
        if args is None:
            print("âŒ argsä»ç„¶ä¸ºNone")
            return False
        
        print(f"âœ… argsç±»å‹: {type(args)}")
        print(f"âœ… æ¶æ„: {getattr(args, 'arch', 'N/A')}")
        print(f"âœ… ä»»åŠ¡: {getattr(args, 'task', 'N/A')}")
        
        # å°è¯•å¯¼å…¥fairseqå¹¶æµ‹è¯•æ¨¡å‹åŠ è½½
        try:
            from fairseq import checkpoint_utils
            
            # æµ‹è¯•åŠ è½½æ¨¡å‹
            print("ğŸ” æµ‹è¯•æ¨¡å‹åŠ è½½...")
            models, model_args = checkpoint_utils.load_model_ensemble([checkpoint_path])
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            print(f"âœ… åŠ è½½çš„æ¨¡å‹æ•°é‡: {len(models)}")
            
            return True
            
        except Exception as e:
            print(f"âš ï¸  æ¨¡å‹åŠ è½½æµ‹è¯•å¤±è´¥: {e}")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    print("ğŸ”§ Checkpoint Argsä¿®å¤å·¥å…·")
    print("=" * 80)
    
    try:
        ROOT_PATH, FAIRSEQ = setup_environment()
        print(f"âœ… ç¯å¢ƒè®¾ç½®å®Œæˆ")
    except Exception as e:
        print(f"âŒ ç¯å¢ƒè®¾ç½®å¤±è´¥: {e}")
        return
    
    # ä¿®å¤ä¸¤ä¸ªæ¨¡å‹
    checkpoints = [
        "pdec_work/checkpoints/europarl_test/1/checkpoint_best.pt",
        "pdec_work/checkpoints/europarl_continue_5epochs/checkpoint_best.pt"
    ]
    
    for checkpoint_path in checkpoints:
        print(f"\n{'='*80}")
        
        if fix_checkpoint_args(checkpoint_path):
            # æµ‹è¯•ä¿®å¤åçš„æ–‡ä»¶
            fixed_path = checkpoint_path.replace('.pt', '_fixed.pt')
            if test_fixed_checkpoint(fixed_path):
                print(f"\nğŸ‰ {checkpoint_path} ä¿®å¤æˆåŠŸ!")
                print(f"ğŸ’¡ ä½¿ç”¨ä¿®å¤åçš„æ–‡ä»¶: {fixed_path}")
            else:
                print(f"\nâš ï¸  {checkpoint_path} ä¿®å¤å®Œæˆä½†æµ‹è¯•å¤±è´¥")
        else:
            print(f"\nâŒ {checkpoint_path} ä¿®å¤å¤±è´¥")
    
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("1. ä½¿ç”¨ä¿®å¤åçš„checkpointæ–‡ä»¶è¿›è¡Œç¿»è¯‘æµ‹è¯•")
    print("2. æ›´æ–°è®­ç»ƒè„šæœ¬ä½¿ç”¨ä¿®å¤åçš„æ–‡ä»¶")

if __name__ == "__main__":
    main() 