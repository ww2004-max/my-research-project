#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Europarl dataset training script for PhasedDecoder (ä¸ä½¿ç”¨--user-diræ–¹æ³•)
é€šè¿‡ç›´æ¥ä¿®æ”¹Pythonè·¯å¾„æ¥åŠ è½½PhasedDecoderæ¨¡å—
"""

import os
import sys
import subprocess
import time

def setup_phaseddecoder():
    """å°†PhasedDecoderæ¨¡å—æ·»åŠ åˆ°Pythonè·¯å¾„ä¸­"""
    # æ·»åŠ PhasedDecoderåˆ°Pythonè·¯å¾„
    phaseddecoder_path = r"C:\Users\33491\PycharmProjects\machine\fairseq\models\PhasedDecoder"
    if phaseddecoder_path not in sys.path:
        sys.path.insert(0, phaseddecoder_path)
    
    # å¯¼å…¥æ¨¡å—ä»¥ç¡®ä¿æ³¨å†Œ
    try:
        import models.transformer_pdec
        print("âœ… PhasedDecoderæ¨¡å—æˆåŠŸåŠ è½½å¹¶æ³¨å†Œ")
        return True
    except Exception as e:
        print(f"âŒ PhasedDecoderæ¨¡å—åŠ è½½å¤±è´¥: {e}")
        return False

def main():
    print("å¼€å§‹GPUåŠ é€Ÿçš„Europarlè®­ç»ƒæµç¨‹ (æ— --user-dirç‰ˆæœ¬)...")
    
    # è®¾ç½®è·¯å¾„å’Œå‚æ•°
    ROOT_PATH = r"C:\Users\33491\PycharmProjects\machine"
    DATA_BIN = r"C:\Users\33491\PycharmProjects\machine\fairseq\models\ZeroTrans\europarl_scripts\build_data\europarl_15-bin"
    FAIRSEQ = os.path.join(ROOT_PATH, "fairseq")
    WORK_PATH = os.path.join(ROOT_PATH, "pdec_work")
    
    # è®­ç»ƒå‚æ•°
    METHOD = "europarl_pdec"
    ID = "1"
    
    # æ¨¡å‹å‚æ•° (åŸºäºTEDé…ç½®)
    ENC = 6
    DEC = 6
    BIAS = 1
    ADAPTION = 'True'
    DROP = 0.1
    INNER = 2048
    CONTRASTIVE = 'True'
    POSITION = 6
    TYPE = 'enc'
    T = 1.0
    DIM = 512
    MODE = 1
    SEED = 0
    
    # åˆ›å»ºç›®å½•
    checkpoint_dir = os.path.join(WORK_PATH, "checkpoints", METHOD, ID)
    logs_dir = os.path.join(WORK_PATH, "logs", METHOD)
    results_dir = os.path.join(WORK_PATH, "results", METHOD, ID)
    
    for directory in [checkpoint_dir, logs_dir, results_dir]:
        os.makedirs(directory, exist_ok=True)
        print(f"åˆ›å»ºç›®å½•: {directory}")
    
    # è®¾ç½®PhasedDecoderæ¨¡å—
    if not setup_phaseddecoder():
        print("âŒ æ— æ³•åŠ è½½PhasedDecoderæ¨¡å—ï¼Œé€€å‡º")
        return
    
    # æ£€æŸ¥CUDA
    print("æ£€æŸ¥CUDAçŠ¶æ€...")
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
            print(f"å½“å‰GPU: {torch.cuda.get_device_name(0)}")
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return
    
    # åˆ‡æ¢åˆ°fairseqç›®å½•
    original_dir = os.getcwd()
    os.chdir(FAIRSEQ)
    print(f"åˆ‡æ¢åˆ°ç›®å½•: {os.getcwd()}")
    
    # æ„å»ºè®­ç»ƒå‘½ä»¤ - ä¸ä½¿ç”¨--user-dir
    train_cmd = [
        "python", "-m", "fairseq_cli.train", DATA_BIN,
        # æ³¨æ„ï¼šä¸ä½¿ç”¨ --user-dir å‚æ•°
        "--seed", str(SEED),
        "--fp16",
        "--ddp-backend=no_c10d",
        "--arch", f"transformer_pdec_{ENC}_e_{DEC}_d",
        "--task", "translation_multi_simple_epoch",
        "--sampling-method", "temperature",
        "--sampling-temperature", "5",
        "--attention-position-bias", str(BIAS),
        "--adaption-flag", ADAPTION,
        "--adaption-inner-size", str(INNER),
        "--adaption-dropout", str(DROP),
        "--contrastive-flag", CONTRASTIVE,
        "--contrastive-type", TYPE,
        "--dim", str(DIM),
        "--mode", str(MODE),
        "--cl-position", str(POSITION),
        "--temperature", str(T),
        "--langs", "en,de,es,it",
        "--lang-pairs", "en-de,de-en,en-es,es-en,en-it,it-en",
        "--encoder-langtok", "tgt",
        "--criterion", "label_smoothed_cross_entropy_instruction",
        "--label-smoothing", "0.1",
        "--optimizer", "adam",
        "--adam-betas", "(0.9,0.98)",
        "--lr", "0.0005",
        "--lr-scheduler", "inverse_sqrt",
        "--warmup-updates", "1000",  # å‡å°‘warmupæ­¥æ•°
        "--max-epoch", "1",  # åªè®­ç»ƒ1ä¸ªepochè¿›è¡Œæµ‹è¯•
        "--max-tokens", "1000",  # å‡å°‘tokenæ•°è¿›è¡Œæµ‹è¯•
        "--share-all-embeddings",
        "--weight-decay", "0.0001",
        "--no-epoch-checkpoints",
        "--no-progress-bar",
        "--keep-best-checkpoints", "1",
        "--log-interval", "50",  # æ›´é¢‘ç¹çš„æ—¥å¿—
        "--log-format", "simple",
        "--save-dir", checkpoint_dir
    ]
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env = os.environ.copy()
    env["CUDA_VISIBLE_DEVICES"] = "0"  # ä½¿ç”¨å•GPU
    env["PYTHONPATH"] = FAIRSEQ + os.pathsep + env.get("PYTHONPATH", "")
    
    # è®°å½•è®­ç»ƒå‘½ä»¤
    log_file = os.path.join(logs_dir, f"{ID}.log")
    print(f"è®­ç»ƒå‘½ä»¤: {' '.join(train_cmd)}")
    print(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    # å¼€å§‹è®­ç»ƒ
    print("ğŸš€ å¼€å§‹GPUæ¨¡å‹è®­ç»ƒ...")
    start_time = time.time()
    
    try:
        with open(log_file, 'w', encoding='utf-8') as f:
            result = subprocess.run(
                train_cmd,
                env=env,
                stdout=f,
                stderr=subprocess.STDOUT,
                text=True,
                cwd=FAIRSEQ
            )
        
        end_time = time.time()
        training_time = end_time - start_time
        
        if result.returncode == 0:
            print(f"âœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼è€—æ—¶: {training_time/60:.2f}åˆ†é’Ÿ")
            print(f"æ£€æŸ¥ç‚¹ä¿å­˜åœ¨: {checkpoint_dir}")
            print(f"è®­ç»ƒæ—¥å¿—: {log_file}")
        else:
            print(f"âŒ è®­ç»ƒå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            print(f"è¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶: {log_file}")
            
            # æ˜¾ç¤ºæœ€å20è¡Œæ—¥å¿—
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    print("\næœ€å20è¡Œæ—¥å¿—:")
                    for line in lines[-20:]:
                        print(line.rstrip())
            except Exception as e:
                print(f"æ— æ³•è¯»å–æ—¥å¿—æ–‡ä»¶: {e}")
    
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")
    
    finally:
        # æ¢å¤åŸå§‹ç›®å½•
        os.chdir(original_dir)
        print(f"æ¢å¤ç›®å½•: {os.getcwd()}")

if __name__ == "__main__":
    main() 